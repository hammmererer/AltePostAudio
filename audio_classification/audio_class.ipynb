{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8734f6b5",
   "metadata": {},
   "source": [
    "# Audio Classification System\n",
    "\n",
    "## Overview\n",
    "This notebook implements an automated audio classification system that:\n",
    "- Analyzes audio files with the YAMNet model\n",
    "- Performs AI-based categorization with OpenAI GPT-4\n",
    "- Exports results in XML and CSV formats\n",
    "- Generates JSON files for further processing\n",
    "\n",
    "## How it Works\n",
    "1. **Audio Analysis**: YAMNet extracts acoustic features from audio files\n",
    "2. **AI Classification**: GPT-4 evaluates the audio against predefined categories\n",
    "3. **Export**: Results are saved in structured formats\n",
    "\n",
    "## Prerequisites\n",
    "- Python environment with TensorFlow, OpenAI API\n",
    "- `classes.csv` with category definitions in the same folder\n",
    "- Audio files in the specified directory\n",
    "- OpenAI API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8617648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DEPENDENCIES & IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "# Install dependencies (run once if not already installed)\n",
    "# !pip install tensorflow tensorflow-hub librosa openai pandas\n",
    "\n",
    "# Standard library imports\n",
    "import os                    # File system operations\n",
    "import datetime             # Timestamps for metadata\n",
    "import re                   # Regular expressions for text processing\n",
    "import json                 # JSON file processing\n",
    "import sys                  # System-specific parameters\n",
    "from pathlib import Path    # Modern path handling\n",
    "from xml.etree.ElementTree import Element, SubElement, ElementTree, tostring  # XML creation\n",
    "from xml.dom import minidom # XML formatting\n",
    "\n",
    "# Machine Learning & Audio Processing\n",
    "import tensorflow as tf     # TensorFlow for YAMNet model\n",
    "import tensorflow_hub as hub  # TensorFlow Hub for pre-trained models\n",
    "import librosa              # Audio analysis and processing\n",
    "import numpy as np          # Numerical computations\n",
    "\n",
    "# Data Processing & AI\n",
    "import pandas as pd         # Tabular data processing\n",
    "from openai import OpenAI   # OpenAI API for GPT-4 classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# ── Path Configuration ────────────────────────────────────────────────────────\n",
    "# Main directory with audio files (recursive search for .wav, .mp3, .flac, .ogg)\n",
    "folder_path = \"/Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3\"\n",
    "\n",
    "# CSV file with category definitions (must contain \"Label\" and \"Meaning Sound\" columns)\n",
    "csv_path = \"classes.csv\"  # Relative path - CSV is in the same folder as the notebook\n",
    "\n",
    "# Output directory for XML files (preserves folder structure)\n",
    "xml_output_dir = \"/Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3\"\n",
    "\n",
    "# ── OpenAI API Configuration ──────────────────────────────────────────────────\n",
    "# IMPORTANT: Replace the API key with your own or use environment variables\n",
    "# For production: client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "client = OpenAI(api_key=\"sk-proj-YOUR-API-KEY-HERE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386097f9",
   "metadata": {},
   "source": [
    "## 1. Model Initialization and Category Loading\n",
    "\n",
    "In this section:\n",
    "- The YAMNet model is loaded (Google's AudioSet model)\n",
    "- Category definitions are read from the CSV file\n",
    "- Audio files are searched in the directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59470173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 audio files.\n",
      "\n",
      "Processing PerryComo_MagicMoments.wav...\n",
      "  → XML saved: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/PerryComo_MagicMoments.xml\n",
      "\n",
      "Processing Palestrina_MissaAeternaSanctus.wav...\n",
      "  → XML saved: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/Palestrina_MissaAeternaSanctus.xml\n",
      "\n",
      "Processing Glockenschlag1.wav...\n",
      "  → XML saved: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/Glockenschlag1.xml\n",
      "\n",
      "Processing Glockenschlag2.wav...\n",
      "  → XML saved: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/Glockenschlag2.xml\n",
      "\n",
      "Results saved to: audio_classification_results.csv\n",
      "XMLs in: /Users/jonashammerer/Documents/25_projekte/01_alte_post/6 classification/classification_v0.2/xml_outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# MODEL INITIALIZATION AND CATEGORY LOADING\n",
    "# =============================================================================\n",
    "\n",
    "# ── Load YAMNet Model ─────────────────────────────────────────────────────────\n",
    "# YAMNet is a pre-trained model from Google for audio classification\n",
    "# It can recognize 521 different audio classes (AudioSet dataset)\n",
    "print(\"Loading YAMNet model...\")\n",
    "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")\n",
    "\n",
    "# Download and load YAMNet class mapping\n",
    "class_map_path = tf.keras.utils.get_file(\n",
    "    'yamnet_class_map.csv',\n",
    "    'https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv'\n",
    ")\n",
    "class_names = [line.split(',')[2] for line in open(class_map_path, encoding=\"utf-8\").readlines()[1:]]\n",
    "print(f\"YAMNet model loaded with {len(class_names)} audio classes\")\n",
    "\n",
    "# ── Load Categories from CSV File ─────────────────────────────────────────────\n",
    "# The CSV file must contain \"Label\" and \"Meaning Sound\" columns\n",
    "print(f\"Loading categories from: {csv_path}\")\n",
    "category_df = pd.read_csv(csv_path)\n",
    "category_df = category_df.dropna(subset=[\"Label\", \"Meaning Sound\"])\n",
    "categories = category_df[\"Label\"].tolist()\n",
    "descriptions = category_df[\"Meaning Sound\"].tolist()\n",
    "instruction_block = \"\\n\".join([f\"{cat}: {desc}\" for cat, desc in zip(categories, descriptions)])\n",
    "\n",
    "print(f\"Loaded categories: {categories}\")\n",
    "\n",
    "# ── Define LLM Prompt for GPT-4 ───────────────────────────────────────────────\n",
    "# This prompt instructs GPT-4 to provide a value, confidence,\n",
    "# and reasoning for each category\n",
    "system_message = f\"\"\"\n",
    "You are an expert in perceptual sound classification.\n",
    "You will receive audio analysis data and return, for EVERY category below,\n",
    "(1) a value between 0 and 1 (how strongly the sound fits),\n",
    "(2) a confidence between 0 and 1 (your confidence in that value),\n",
    "(3) a single-sentence reasoning.\n",
    "\n",
    "Here are the category definitions to use for all requests:\n",
    "\n",
    "{instruction_block}\n",
    "\n",
    "STRICT OUTPUT FORMAT (one line per category; no extra text):\n",
    "Category | value | confidence | reasoning\n",
    "\"\"\"\n",
    "\n",
    "# ── Collect Audio Files ───────────────────────────────────────────────────────\n",
    "# Recursive search for audio files in the specified directory\n",
    "print(f\"Searching for audio files in: {folder_path}\")\n",
    "audio_files = []\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".wav\", \".mp3\", \".flac\", \".ogg\")):\n",
    "            full_path = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(full_path, folder_path)\n",
    "            audio_files.append((full_path, rel_path))\n",
    "\n",
    "print(f\"Found: {len(audio_files)} audio files\")\n",
    "for full_path, rel_path in audio_files:\n",
    "    print(f\"  - {rel_path}\")\n",
    "\n",
    "# ── Utils ─────────────────────────────────────────────────────────────────────\n",
    "def normalize(text):\n",
    "    return re.sub(r'\\W+', '', str(text)).lower()\n",
    "\n",
    "normalized_categories = {normalize(cat): cat for cat in categories}\n",
    "\n",
    "# Robust parser for \"Category | value | confidence | reasoning\"\n",
    "line_regexes = [\n",
    "    re.compile(r\"^\\s*(.+?)\\s*\\|\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*(.+?)\\s*$\"),\n",
    "    re.compile(r\"^\\s*(.+?)\\s*:\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*(.+?)\\s*$\"),\n",
    "    re.compile(r\"^\\s*(.+?)\\s*:\\s*val(?:ue)?\\s*=\\s*([01](?:\\.\\d+)?)\\s*,\\s*conf(?:idence)?\\s*=\\s*([01](?:\\.\\d+)?)\\s*,\\s*reason(?:ing)?\\s*=\\s*(.+?)\\s*$\")\n",
    "]\n",
    "\n",
    "def parse_llm_lines(raw: str):\n",
    "    out = {}\n",
    "    for line in raw.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        for rgx in line_regexes:\n",
    "            m = rgx.match(line)\n",
    "            if m:\n",
    "                key_raw, val_str, conf_str, reason = m.groups()\n",
    "                key_norm = normalize(key_raw)\n",
    "                if key_norm in normalized_categories:\n",
    "                    cat = normalized_categories[key_norm]\n",
    "                    try:\n",
    "                        val = float(val_str)\n",
    "                        conf = float(conf_str)\n",
    "                        # clip defensively to [0,1]\n",
    "                        val = max(0.0, min(1.0, val))\n",
    "                        conf = max(0.0, min(1.0, conf))\n",
    "                        out[cat] = (val, conf, reason.strip())\n",
    "                    except:\n",
    "                        pass\n",
    "                break\n",
    "    # Ensure all categories present; fill missing with zeros and note reason\n",
    "    for cat in categories:\n",
    "        if cat not in out:\n",
    "            out[cat] = (0.0, 0.0, \"Not provided by model; defaulted to 0 with low confidence.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def pretty_xml(elem) -> bytes:\n",
    "    # Convert Element → bytes with xml.etree\n",
    "    rough = tostring(elem, encoding=\"utf-8\")\n",
    "    # Re-parse with minidom for pretty printing\n",
    "    parsed = minidom.parseString(rough)\n",
    "    return parsed.toprettyxml(indent=\"  \", encoding=\"utf-8\")\n",
    "\n",
    "def safe_xml_filename(rel_path: str) -> str:\n",
    "    # flatten nested paths and swap extension\n",
    "    base = re.sub(r\"[\\\\/]+\", \"__\", rel_path)\n",
    "    base = re.sub(r\"[^A-Za-z0-9_.-]+\", \"_\", base)\n",
    "    base = os.path.splitext(base)[0] + \".xml\"\n",
    "    return base\n",
    "\n",
    "# ── Analyze one audio file ────────────────────────────────────────────────────\n",
    "def analyze_audio(file_path):\n",
    "    waveform, sr = librosa.load(file_path, sr=16000)\n",
    "    scores, _, _ = yamnet_model(waveform)\n",
    "    mean_scores = tf.reduce_mean(scores, axis=0).numpy()\n",
    "    top_n = 15\n",
    "    top_indices = mean_scores.argsort()[-top_n:][::-1]\n",
    "    top_labels = [(class_names[i], float(mean_scores[i])) for i in top_indices]\n",
    "    top_3_labels = \", \".join([label for label, _ in top_labels[:3]])\n",
    "\n",
    "    # Audio features\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(waveform)), ref=np.max)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=waveform, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=waveform, sr=sr)\n",
    "    dominant_freq = np.argmax(np.mean(np.abs(D), axis=1)) * (sr / 2 / D.shape[0])\n",
    "    rms = float(librosa.feature.rms(y=waveform).mean())\n",
    "\n",
    "    label_str = \", \".join([f\"{l} ({s:.2f})\" for l, s in top_labels])\n",
    "\n",
    "    # Category scoring (value + confidence + reasoning)\n",
    "    user_message = f\"\"\"\n",
    "Audio analysis:\n",
    "\n",
    "YAMNet top labels: {label_str}\n",
    "Dominant frequency: {dominant_freq:.2f} Hz\n",
    "Spectral centroid (mean): {float(np.mean(spectral_centroid)):.2f}\n",
    "Spectral bandwidth (mean): {float(np.mean(spectral_bandwidth)):.2f}\n",
    "Average loudness (RMS): {rms:.4f}\n",
    "\n",
    "Return one line PER CATEGORY exactly as:\n",
    "Category | value | confidence | reasoning\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    raw_output = response.choices[0].message.content\n",
    "    triples = parse_llm_lines(raw_output)  # {cat: (value, confidence, reasoning)}\n",
    "\n",
    "    # Plain-language description for metadata\n",
    "    desc_prompt = f\"\"\"\n",
    "Describe this sound in 1–2 plain English sentences for a metadata 'reasoning' field.\n",
    "Focus on perceptual qualities and context.\n",
    "\n",
    "YAMNet: {label_str}\n",
    "Dominant frequency: {dominant_freq:.2f} Hz\n",
    "Spectral centroid: {float(np.mean(spectral_centroid)):.2f}\n",
    "Spectral bandwidth: {float(np.mean(spectral_bandwidth)):.2f}\n",
    "Loudness (RMS): {rms:.4f}\n",
    "\"\"\"\n",
    "    desc_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in acoustic and perceptual sound description.\"},\n",
    "            {\"role\": \"user\", \"content\": desc_prompt}\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    sound_description = desc_response.choices[0].message.content.strip()\n",
    "\n",
    "    return triples, top_3_labels, sound_description\n",
    "\n",
    "# ── XML writer (per file) ─────────────────────────────────────────────────────\n",
    "def write_xml_for_file(rel_path: str, triples: dict, top3: str, summary: str, out_dir: str = xml_output_dir):\n",
    "    root = Element(\"audio_classification\")\n",
    "    metadata = SubElement(root, \"metadata\")\n",
    "    reasoning_meta = SubElement(metadata, \"reasoning\")\n",
    "    reasoning_meta.text = f\"{summary} | Top-3 YAMNet: {top3}\"\n",
    "    analysis_date = SubElement(metadata, \"analysis_date\")\n",
    "    analysis_date.text = datetime.date.today().isoformat()\n",
    "\n",
    "    for cat in categories:\n",
    "        val, conf, why = triples[cat]\n",
    "        p = SubElement(root, \"parameter\")\n",
    "        p.set(\"name\", str(cat))\n",
    "        p.set(\"value\", f\"{float(val):.4f}\")\n",
    "        p.set(\"confidence\", f\"{float(conf):.4f}\")\n",
    "        p.set(\"reasoning\", why)\n",
    "\n",
    "    xml_bytes = pretty_xml(root)\n",
    "\n",
    "    # --- Preserve folder structure: rel_path -> out_dir/<rel_path>.xml ---\n",
    "    xml_rel_path = Path(rel_path).with_suffix(\".xml\")     # e.g. sub/xy.wav -> sub/xy.xml\n",
    "    xml_path = Path(out_dir) / xml_rel_path\n",
    "\n",
    "    # Create subfolders\n",
    "    xml_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(xml_path, \"wb\") as f:\n",
    "        f.write(xml_bytes)\n",
    "\n",
    "    return str(xml_path)\n",
    "\n",
    "\n",
    "# ── Batch process: CSV + XMLs ─────────────────────────────────────────────────\n",
    "xml_output_dir = \"xml_outputs\"\n",
    "csv_rows = []\n",
    "\n",
    "for full_path, rel_path in audio_files:\n",
    "    print(f\"\\nProcessing {rel_path}...\")\n",
    "    triples, top3, description = analyze_audio(full_path)\n",
    "\n",
    "    # CSV entry\n",
    "    row = {\"File\": rel_path, \"Top 3 Labels\": top3, \"LLM Description\": description}\n",
    "    for cat in categories:\n",
    "        val, conf, why = triples[cat]\n",
    "        row[cat] = val\n",
    "        row[f\"{cat}__confidence\"] = conf\n",
    "        row[f\"{cat}__reason\"] = why\n",
    "    csv_rows.append(row)\n",
    "\n",
    "    # Write XML\n",
    "    xml_path = write_xml_for_file(rel_path, triples, top3, description)\n",
    "    print(f\"  → XML saved: {xml_path}\")\n",
    "\n",
    "# Save CSV overview\n",
    "df = pd.DataFrame(csv_rows)\n",
    "csv_output_path = \"audio_classification_results.csv\"\n",
    "df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n",
    "print(f\"\\nResults saved to: {csv_output_path}\\nXMLs in: {os.path.abspath(xml_output_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cec9ed",
   "metadata": {},
   "source": [
    "## 2. Utility Functions\n",
    "\n",
    "These functions support creating JSON files for the Max patch:\n",
    "- Text normalization for category comparison\n",
    "- Parsing of GPT-4 responses\n",
    "- XML formatting and filename safety\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b496623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3\n",
      "Base Output: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3\n",
      "Gefundene WAV-Dateien: [PosixPath('/Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/PerryComo_MagicMoments.wav'), PosixPath('/Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/Palestrina_MissaAeternaSanctus.wav'), PosixPath('/Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/Glockenschlag1.wav'), PosixPath('/Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/Glockenschlag2.wav')]\n",
      "Fertig. 4 JSON-Dateien gespeichert in: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/data-Ablp\n",
      "Fertig. 4 JSON-Dateien gespeichert in: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/data-Bblp\n",
      "Fertig. 4 JSON-Dateien gespeichert in: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/data-grain\n",
      "Fertig. 4 JSON-Dateien gespeichert in: /Users/jonashammerer/Documents/25_projekte/01_alte_post/0material/material_3/data-stretch\n",
      "Alle Ordner wurden befüllt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def build_json(name: str) -> dict:\n",
    "    return {\n",
    "        \"pattrstorage\": {\n",
    "            \"name\": name,\n",
    "            \"slots\": {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "def generate_json_for_wavs_multi_dirs(input_dir=None, base_output_dir=None):\n",
    "    if input_dir is None:\n",
    "        input_dir = folder_path\n",
    "    if base_output_dir is None:\n",
    "        base_output_dir = folder_path\n",
    "\n",
    "    input_dir = Path(input_dir)\n",
    "    base_output_dir = Path(base_output_dir)\n",
    "\n",
    "    # Folders and associated names\n",
    "    target_dirs_and_names = [\n",
    "        (\"data-Ablp\", \"blp\"),\n",
    "        (\"data-Bblp\", \"blp\"),\n",
    "        (\"data-grain\", \"grain\"),\n",
    "        (\"data-stretch\", \"stretch\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"Input: {input_dir}\")\n",
    "    print(f\"Base Output: {base_output_dir}\")\n",
    "\n",
    "    if not input_dir.exists() or not input_dir.is_dir():\n",
    "        print(f\"Error: Input folder does not exist or is not a folder: {input_dir}\", file=sys.stderr)\n",
    "        return 1\n",
    "\n",
    "    wav_paths = [p for p in input_dir.rglob(\"*\") if p.is_file() and p.suffix.lower() == \".wav\"]\n",
    "    print(f\"Found WAV files: {wav_paths}\")\n",
    "\n",
    "    if not wav_paths:\n",
    "        print(\"Note: No .wav files found.\")\n",
    "        return 0\n",
    "\n",
    "    for target, name in target_dirs_and_names:\n",
    "        output_dir = base_output_dir / target\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        used_names = {}\n",
    "        for wav in wav_paths:\n",
    "            base_name = wav.stem\n",
    "            json_name = f\"{base_name}.json\"\n",
    "            json_out = output_dir / json_name\n",
    "\n",
    "            # Avoid collisions\n",
    "            if json_out.exists():\n",
    "                count = used_names.get(base_name, 1)\n",
    "                while True:\n",
    "                    json_name = f\"{base_name}_{count}.json\"\n",
    "                    json_out = output_dir / json_name\n",
    "                    if not json_out.exists():\n",
    "                        used_names[base_name] = count + 1\n",
    "                        break\n",
    "                    count += 1\n",
    "\n",
    "            payload = build_json(name)\n",
    "            with json_out.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(payload, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Done. {len(wav_paths)} JSON files saved in: {output_dir}\")\n",
    "\n",
    "    print(\"All folders have been populated.\")\n",
    "    return 0\n",
    "\n",
    "generate_json_for_wavs_multi_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecab7d3",
   "metadata": {},
   "source": [
    "## 3. Audio Analysis Functions\n",
    "\n",
    "These functions perform the actual audio analysis:\n",
    "- `analyze_audio()`: Analyzes an audio file with YAMNet and GPT-4\n",
    "- `write_xml_for_file()`: Creates XML output for each file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ed32de",
   "metadata": {},
   "source": [
    "## 4. JSON Generation for Further Processing\n",
    "\n",
    "This section creates JSON files for integration into other systems:\n",
    "- Creates structured JSON files for each audio file\n",
    "- Organizes files into different categories (blp, grain, stretch)\n",
    "- Prevents name conflicts through automatic numbering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c11e4e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What was created:\n",
    "\n",
    "1. **CSV File**: `audio_classification_results.csv`\n",
    "   - Overview table with all classification results\n",
    "   - Contains values, confidences, and reasoning for each category\n",
    "\n",
    "2. **XML Files**: Individual XML files for each audio file\n",
    "   - Structured metadata with analysis date\n",
    "   - Detailed parameters for each category\n",
    "   - Preserves original folder structure\n",
    "\n",
    "3. **JSON Files**: For integration into other systems\n",
    "   - `data-Ablp/` and `data-Bblp/`: Buffer Loop Player\n",
    "   - `data-grain/`: Granular Synthesizer  \n",
    "   - `data-stretch/`: Time-Stretch Player\n",
    "\n",
    "### Next Steps:\n",
    "- Review the results in the CSV file\n",
    "- Use the XML files for detailed analyses\n",
    "- Integrate the JSON files into your audio processing pipeline\n",
    "\n",
    "### Customization:\n",
    "- Change `folder_path` for other audio directories\n",
    "- Adapt the categories in `classes.csv` to your needs\n",
    "- Modify the JSON structure depending on your use case\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
