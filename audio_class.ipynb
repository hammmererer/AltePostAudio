{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75622295",
   "metadata": {},
   "source": [
    "# Audio Classification System\n",
    "\n",
    "## Overview\n",
    "This notebook implements an automated audio classification system that:\n",
    "- Analyzes audio files with the YAMNet model\n",
    "- Performs AI-based categorization with OpenAI GPT-4\n",
    "- Exports results in XML and CSV formats\n",
    "- Generates JSON preset files for Max patch\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ PREREQUISITES & INSTALLATION\n",
    "\n",
    "### System Requirements\n",
    "- **Python 3.8 or newer** (Python 3.9-3.11 recommended)\n",
    "- **8GB RAM minimum** (16GB recommended for processing many files)\n",
    "- **Internet connection** (for downloading models and API access)\n",
    "\n",
    "### Step 1: Install Python\n",
    "If you don't have Python installed:\n",
    "\n",
    "**Windows:**\n",
    "1. Download from: https://www.python.org/downloads/\n",
    "2. During installation, check âœ… \"Add Python to PATH\"\n",
    "3. Complete the installation\n",
    "\n",
    "**macOS:**\n",
    "1. Python 3 is usually pre-installed\n",
    "2. Check version: Open Terminal and type `python3 --version`\n",
    "3. If not installed, download from: https://www.python.org/downloads/\n",
    "\n",
    "### Step 2: Install Required Libraries\n",
    "Open your **Terminal** (macOS) or **Command Prompt** (Windows) and run:\n",
    "\n",
    "```bash\n",
    "pip install tensorflow tensorflow-hub librosa openai pandas\n",
    "```\n",
    "\n",
    "**If you encounter errors**, try:\n",
    "```bash\n",
    "pip3 install tensorflow tensorflow-hub librosa openai pandas\n",
    "```\n",
    "\n",
    "**Note:** Installation may take 5-10 minutes as TensorFlow is a large library.\n",
    "\n",
    "### Step 3: Get OpenAI API Key\n",
    "1. Go to: https://platform.openai.com/api-keys\n",
    "2. Sign up or log in to your OpenAI account\n",
    "3. Click \"Create new secret key\"\n",
    "4. Copy the key (you'll need it in Cell 2)\n",
    "\n",
    "**Important:** Keep your API key private! Never share it publicly.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ HOW TO USE THIS NOTEBOOK:\n",
    "\n",
    "### âœï¸ STEP 1: Configure Settings (Cell 2 Below)\n",
    "- **YOU MUST EDIT** the configuration cell (Cell 2)\n",
    "- Set your folder path and API key\n",
    "- âš ï¸ **CRITICAL**: Ensure audio files have NO umlauts, accents, or spaces!\n",
    "\n",
    "### â–¶ï¸ STEP 2: Run All Cells  \n",
    "- After configuration, run all cells in order\n",
    "- **DO NOT MODIFY** code in cells 3-5\n",
    "- Just click \"Run\" on each cell\n",
    "\n",
    "### âœ… STEP 3: Check Output\n",
    "- Classification XMLs will be saved with your audio files\n",
    "- JSON preset folders will be created in your material folder\n",
    "- See summary at the end for next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff0b9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âœï¸ CELL 1: CONFIGURATION - YOU MUST EDIT THIS!\n",
    "\n",
    "âš ï¸ **REQUIRED: Edit the values in the cell below**\n",
    "\n",
    "**What to change:**\n",
    "1. **folder_path**: Full path to your new audio material folder\n",
    "2. **api_key**: Your OpenAI API key (get from: https://platform.openai.com/api-keys)\n",
    "\n",
    "**File Naming Requirements (CRITICAL!):**\n",
    "- âŒ NO umlauts (Ã¤, Ã¶, Ã¼)\n",
    "- âŒ NO accents (Ã©, Ã , Ã±)  \n",
    "- âŒ NO spaces (use underscores _)\n",
    "\n",
    "**Examples:**\n",
    "```\n",
    "âŒ Wrong: \"Paco De LucÃ­a.wav\"\n",
    "âœ… Correct: \"Paco_De_Lucia.wav\"\n",
    "\n",
    "âŒ Wrong: \"MÃ¼ller & SÃ¶hne.wav\"\n",
    "âœ… Correct: \"Mueller_und_Soehne.wav\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e651de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âœï¸ CONFIGURATION - EDIT THESE VALUES!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€ Your Audio Material Folder Path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Replace with the FULL path to your new audio material folder\n",
    "# \n",
    "# Example Windows: \n",
    "#   folder_path = \"C:/Users/YourName/Documents/APO_Main/apo_material/new_sounds\"\n",
    "# \n",
    "# Example macOS: \n",
    "#   folder_path = \"/Users/YourName/Documents/APO_Main/apo_material/new_sounds\"\n",
    "\n",
    "folder_path = r\"folder\"  # â† CHANGE THIS!\n",
    "\n",
    "# â”€â”€ Your OpenAI API Key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Replace with your OpenAI API key\n",
    "# Get your key from: https://platform.openai.com/api-keys\n",
    "\n",
    "api_key = \"your_open_ai_api_key\"  # â† CHANGE THIS!\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš ï¸ DO NOT EDIT BELOW THIS LINE!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Internal configuration (automatically set)\n",
    "csv_path = \"classes.csv\"  # Category definitions (must be in same folder as this notebook)\n",
    "xml_output_dir = folder_path  # XMLs will be saved in the material folder\n",
    "\n",
    "print(\"âœ… Configuration loaded!\")\n",
    "print(f\"   Folder: {folder_path}\")\n",
    "print(f\"   Categories file: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2917b4eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# â–¶ï¸ CELLS 2-4: RUN THESE CELLS - DO NOT MODIFY!\n",
    "\n",
    "**Instructions:**\n",
    "1. Run Cell 2 (Load Dependencies)\n",
    "2. Run Cell 3 (Initialize Model & Analyze)\n",
    "3. Run Cell 4 (Generate JSON Presets)\n",
    "4. See summary at the end\n",
    "\n",
    "âš ï¸ **Do NOT modify** any code in the cells below!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 2: LOAD DEPENDENCIES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# â–¶ï¸ RUN THIS CELL - DO NOT MODIFY!\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TROUBLESHOOTING: If you get \"ModuleNotFoundError\", the libraries are not \n",
    "# installed. Run this command in your Terminal/Command Prompt:\n",
    "#\n",
    "#   pip install tensorflow tensorflow-hub librosa openai pandas\n",
    "#\n",
    "# Then restart this notebook and try again.\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "print(\"Loading libraries...\")\n",
    "\n",
    "import os, datetime, re, json, sys\n",
    "from pathlib import Path\n",
    "from xml.etree.ElementTree import Element, SubElement, tostring\n",
    "from xml.dom import minidom\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Verify versions\n",
    "print(\"\\nğŸ“¦ Library versions:\")\n",
    "print(f\"   TensorFlow: {tf.__version__}\")\n",
    "print(f\"   Librosa: {librosa.__version__}\")\n",
    "print(f\"   Pandas: {pd.__version__}\")\n",
    "print(f\"   NumPy: {np.__version__}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"\\nâœ… All dependencies loaded successfully!\")\n",
    "print(\"   You can proceed to Cell 3.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da22a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 3: INITIALIZE MODEL & ANALYZE AUDIO FILES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# â–¶ï¸ RUN THIS CELL - DO NOT MODIFY!\n",
    "\n",
    "# Load YAMNet model\n",
    "print(\"Loading YAMNet model...\")\n",
    "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")\n",
    "class_map_path = tf.keras.utils.get_file('yamnet_class_map.csv',\n",
    "    'https://raw.githubusercontent.com/tensorflow/models/master/research/audioset/yamnet/yamnet_class_map.csv')\n",
    "class_names = [line.split(',')[2] for line in open(class_map_path, encoding=\"utf-8\").readlines()[1:]]\n",
    "print(f\"âœ… YAMNet loaded ({len(class_names)} classes)\\n\")\n",
    "\n",
    "# Load categories\n",
    "print(f\"Loading categories from: {csv_path}\")\n",
    "category_df = pd.read_csv(csv_path).dropna(subset=[\"Label\", \"Meaning Sound\"])\n",
    "categories = category_df[\"Label\"].tolist()\n",
    "descriptions = category_df[\"Meaning Sound\"].tolist()\n",
    "instruction_block = \"\\n\".join([f\"{cat}: {desc}\" for cat, desc in zip(categories, descriptions)])\n",
    "print(f\"âœ… Loaded {len(categories)} categories\\n\")\n",
    "\n",
    "# GPT-4 prompt\n",
    "system_message = f\"\"\"You are an expert in perceptual sound classification.\n",
    "You will receive audio analysis data and return, for EVERY category below,\n",
    "(1) a value between 0 and 1 (how strongly the sound fits),\n",
    "(2) a confidence between 0 and 1 (your confidence in that value),\n",
    "(3) a single-sentence reasoning.\n",
    "\n",
    "Here are the category definitions:\n",
    "{instruction_block}\n",
    "\n",
    "CRITICAL: You MUST return a response for ALL {len(categories)} categories listed above.\n",
    "Do not skip any categories. Use the EXACT category names as shown above.\n",
    "\n",
    "STRICT OUTPUT FORMAT (one line per category; no extra text):\n",
    "Category | value | confidence | reasoning\n",
    "\n",
    "Example:\n",
    "Music | 0.8500 | 0.9000 | Clear melodic structure with vocals\n",
    "Noise - Music | 0.2000 | 0.7000 | Some musical elements but primarily noise-like\n",
    "Micro - Macro | 0.5000 | 0.6000 | Balanced between intimate and expansive qualities\"\"\"\n",
    "\n",
    "# Find audio files\n",
    "print(f\"Searching for audio files in: {folder_path}\")\n",
    "audio_files = []\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".wav\", \".mp3\", \".flac\", \".ogg\")):\n",
    "            full_path = os.path.join(root, file)\n",
    "            audio_files.append((full_path, os.path.relpath(full_path, folder_path)))\n",
    "print(f\"âœ… Found {len(audio_files)} audio files\\n\")\n",
    "\n",
    "# Utility functions\n",
    "def normalize(text):\n",
    "    # More robust normalization: remove all non-alphanumeric, convert to lowercase\n",
    "    return re.sub(r'[^a-z0-9]', '', str(text).lower())\n",
    "\n",
    "normalized_categories = {normalize(cat): cat for cat in categories}\n",
    "\n",
    "# More flexible regex patterns that handle various formats\n",
    "line_regexes = [\n",
    "    # Standard format: Category | value | confidence | reasoning\n",
    "    re.compile(r\"^\\s*(.+?)\\s*\\|\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*(.+?)\\s*$\"),\n",
    "    # Alternative format: Category: value | confidence | reasoning\n",
    "    re.compile(r\"^\\s*(.+?)\\s*:\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*([01](?:\\.\\d+)?)\\s*\\|\\s*(.+?)\\s*$\"),\n",
    "    # Format with equals: Category: value=0.5, confidence=0.8, reasoning=...\n",
    "    re.compile(r\"^\\s*(.+?)\\s*:\\s*value\\s*=\\s*([01](?:\\.\\d+)?)\\s*,\\s*confidence\\s*=\\s*([01](?:\\.\\d+)?)\\s*,\\s*reasoning\\s*=\\s*(.+?)\\s*$\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "def parse_llm_lines(raw):\n",
    "    # Normalize line endings to handle Windows (\\r\\n) vs Unix (\\n)\n",
    "    raw = raw.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    \n",
    "    out = {}\n",
    "    parsed_categories = set()\n",
    "    failed_lines = []  # For debugging\n",
    "    \n",
    "    for line in raw.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        \n",
    "        # Skip lines that look like headers or separators\n",
    "        if line.startswith('---') or line.startswith('===') or 'Category' in line and 'value' in line.lower() and 'confidence' in line.lower():\n",
    "            continue\n",
    "        \n",
    "        matched = False\n",
    "        for rgx in line_regexes:\n",
    "            m = rgx.match(line)\n",
    "            if m:\n",
    "                key_raw, val_str, conf_str, reason = m.groups()\n",
    "                key_norm = normalize(key_raw.strip())\n",
    "                \n",
    "                if key_norm in normalized_categories:\n",
    "                    cat = normalized_categories[key_norm]\n",
    "                    parsed_categories.add(cat)\n",
    "                    try:\n",
    "                        val = max(0.0, min(1.0, float(val_str)))\n",
    "                        conf = max(0.0, min(1.0, float(conf_str)))\n",
    "                        out[cat] = (val, conf, reason.strip())\n",
    "                        matched = True\n",
    "                        break\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        failed_lines.append(f\"Parse error for '{line}': {e}\")\n",
    "                        pass\n",
    "                else:\n",
    "                    # Debug: show what normalized key we got vs what we expected\n",
    "                    # This helps identify if GPT is using different formatting\n",
    "                    pass\n",
    "        \n",
    "        if not matched and line and not line.startswith('#'):\n",
    "            # Try fuzzy matching for category names with special characters\n",
    "            # Check if any part of the line matches a category\n",
    "            line_lower = line.lower()\n",
    "            for cat in categories:\n",
    "                cat_norm = normalize(cat)\n",
    "                # Check if the normalized category name appears in the line\n",
    "                if cat_norm in normalize(line):\n",
    "                    # Try to extract values using a more lenient pattern\n",
    "                    value_match = re.search(r'([01](?:\\.\\d+)?)', line)\n",
    "                    conf_match = re.search(r'([01](?:\\.\\d+)?)', line[line.find('|')+1:] if '|' in line else line)\n",
    "                    if value_match and conf_match:\n",
    "                        try:\n",
    "                            val = max(0.0, min(1.0, float(value_match.group(1))))\n",
    "                            conf = max(0.0, min(1.0, float(conf_match.group(1))))\n",
    "                            # Extract reasoning (everything after the last number)\n",
    "                            reason = line.split('|')[-1].strip() if '|' in line else \"Parsed from alternative format\"\n",
    "                            if cat not in out:\n",
    "                                out[cat] = (val, conf, reason)\n",
    "                                parsed_categories.add(cat)\n",
    "                                matched = True\n",
    "                                break\n",
    "                        except:\n",
    "                            pass\n",
    "    \n",
    "    # Debug: Print which categories were not found\n",
    "    missing = set(categories) - parsed_categories\n",
    "    if missing:\n",
    "        print(f\"âš ï¸  Warning: {len(missing)} categories not found in GPT response: {missing}\")\n",
    "        # Optional: Print a sample of the raw response to help debug\n",
    "        # print(f\"\\nSample of GPT response (first 500 chars):\\n{raw[:500]}\\n\")\n",
    "    \n",
    "    # Fill in missing categories\n",
    "    for cat in categories:\n",
    "        if cat not in out:\n",
    "            out[cat] = (0.0, 0.0, \"Not provided by model.\")\n",
    "    \n",
    "    return out\n",
    "\n",
    "def pretty_xml(elem):\n",
    "    rough = tostring(elem, encoding=\"utf-8\")\n",
    "    return minidom.parseString(rough).toprettyxml(indent=\"  \", encoding=\"utf-8\")\n",
    "\n",
    "def analyze_audio(file_path):\n",
    "    waveform, sr = librosa.load(file_path, sr=16000)\n",
    "    scores, _, _ = yamnet_model(waveform)\n",
    "    mean_scores = tf.reduce_mean(scores, axis=0).numpy()\n",
    "    top_indices = mean_scores.argsort()[-15:][::-1]\n",
    "    top_labels = [(class_names[i], float(mean_scores[i])) for i in top_indices]\n",
    "    top_3_labels = \", \".join([label for label, _ in top_labels[:3]])\n",
    "    \n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(waveform)), ref=np.max)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=waveform, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=waveform, sr=sr)\n",
    "    dominant_freq = np.argmax(np.mean(np.abs(D), axis=1)) * (sr / 2 / D.shape[0])\n",
    "    rms = float(librosa.feature.rms(y=waveform).mean())\n",
    "    label_str = \", \".join([f\"{l} ({s:.2f})\" for l, s in top_labels])\n",
    "    \n",
    "    user_message = f\"\"\"Audio analysis:\n",
    "YAMNet top labels: {label_str}\n",
    "Dominant frequency: {dominant_freq:.2f} Hz\n",
    "Spectral centroid: {float(np.mean(spectral_centroid)):.2f}\n",
    "Spectral bandwidth: {float(np.mean(spectral_bandwidth)):.2f}\n",
    "Average loudness (RMS): {rms:.4f}\n",
    "\n",
    "Return one line PER CATEGORY exactly as:\n",
    "Category | value | confidence | reasoning\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_message},\n",
    "                  {\"role\": \"user\", \"content\": user_message}], temperature=0.2)\n",
    "    triples = parse_llm_lines(response.choices[0].message.content)\n",
    "    \n",
    "    desc_response = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an expert in acoustic sound description.\"},\n",
    "                  {\"role\": \"user\", \"content\": f\"Describe this sound in 1-2 sentences:\\n{label_str}\"}],\n",
    "        temperature=0.5)\n",
    "    description = desc_response.choices[0].message.content.strip()\n",
    "    \n",
    "    return triples, top_3_labels, description\n",
    "\n",
    "def write_xml(rel_path, triples, top3, summary):\n",
    "    root = Element(\"audio_classification\")\n",
    "    metadata = SubElement(root, \"metadata\")\n",
    "    SubElement(metadata, \"reasoning\").text = f\"{summary} | Top-3: {top3}\"\n",
    "    SubElement(metadata, \"analysis_date\").text = datetime.date.today().isoformat()\n",
    "    for cat in categories:\n",
    "        val, conf, why = triples[cat]\n",
    "        p = SubElement(root, \"parameter\")\n",
    "        p.set(\"name\", str(cat))\n",
    "        p.set(\"value\", f\"{float(val):.4f}\")\n",
    "        p.set(\"confidence\", f\"{float(conf):.4f}\")\n",
    "        p.set(\"reasoning\", why)\n",
    "    xml_path = Path(xml_output_dir) / Path(rel_path).with_suffix(\".xml\")\n",
    "    xml_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    xml_path.write_bytes(pretty_xml(root))\n",
    "    return str(xml_path)\n",
    "\n",
    "# Process files\n",
    "print(\"=\"*80 + \"\\nPROCESSING AUDIO FILES\\n\" + \"=\"*80 + \"\\n\")\n",
    "csv_rows = []\n",
    "for idx, (full_path, rel_path) in enumerate(audio_files, 1):\n",
    "    print(f\"[{idx}/{len(audio_files)}] {rel_path}\")\n",
    "    try:\n",
    "        triples, top3, desc = analyze_audio(full_path)\n",
    "        row = {\"File\": rel_path, \"Top 3 Labels\": top3, \"Description\": desc}\n",
    "        for cat in categories:\n",
    "            val, conf, why = triples[cat]\n",
    "            row[cat], row[f\"{cat}__conf\"], row[f\"{cat}__reason\"] = val, conf, why\n",
    "        csv_rows.append(row)\n",
    "        xml_path = write_xml(rel_path, triples, top3, desc)\n",
    "        print(f\"  âœ… XML: {xml_path}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ERROR: {e}\\n\")\n",
    "\n",
    "csv_path_out = os.path.join(folder_path, \"audio_classification_results.csv\")\n",
    "pd.DataFrame(csv_rows).to_csv(csv_path_out, index=False, encoding=\"utf-8\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\nâœ… CLASSIFICATION COMPLETE!\\n\" + \"=\"*80)\n",
    "print(f\"ğŸ“„ CSV: {csv_path_out}\")\n",
    "print(f\"ğŸ“‹ XMLs: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80505d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CELL 4: GENERATE JSON PRESET FILES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# â–¶ï¸ RUN THIS CELL - DO NOT MODIFY!\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\nGENERATING JSON PRESET FILES\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "def build_json(name):\n",
    "    return {\"pattrstorage\": {\"name\": name, \"slots\": {}}}\n",
    "\n",
    "input_dir = Path(folder_path)\n",
    "target_dirs = [(\"data-Ablp\", \"blp\"), (\"data-Bblp\", \"blp\"), \n",
    "               (\"data-grain\", \"grain\"), (\"data-stretch\", \"stretch\")]\n",
    "\n",
    "wav_paths = [p for p in input_dir.rglob(\"*\") if p.is_file() and p.suffix.lower() == \".wav\"]\n",
    "print(f\"Found {len(wav_paths)} WAV files\\n\")\n",
    "\n",
    "for target, name in target_dirs:\n",
    "    output_dir = input_dir / target\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for wav in wav_paths:\n",
    "        json_path = output_dir / f\"{wav.stem}.json\"\n",
    "        json_path.write_text(json.dumps(build_json(name), indent=4, ensure_ascii=False))\n",
    "    print(f\"âœ… {len(wav_paths)} JSON files â†’ {output_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\nâœ… JSON PRESET GENERATION COMPLETE!\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee000ebf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âœ… SUMMARY & NEXT STEPS\n",
    "\n",
    "## What was created:\n",
    "\n",
    "### 1. Classification XMLs âœ…\n",
    "- **Location**: Saved alongside your audio files\n",
    "- **Content**: YAMNet analysis + GPT-4 categorization\n",
    "\n",
    "### 2. CSV Overview âœ…\n",
    "- **File**: `audio_classification_results.csv` in your material folder\n",
    "- **Content**: Complete overview of all classifications\n",
    "\n",
    "### 3. JSON Preset Folders âœ…\n",
    "Created in your material folder:\n",
    "- `data-Ablp/` - Loop Player A presets\n",
    "- `data-Bblp/` - Loop Player B presets  \n",
    "- `data-grain/` - Granular Synthesizer presets\n",
    "- `data-stretch/` - Time-Stretch Player presets\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Next Steps:\n",
    "\n",
    "### 1. Copy Preset Folders to APO_Main\n",
    "```\n",
    "[your_material_folder]/data-Ablp/    â†’ APO_Main/data-Ablp/\n",
    "[your_material_folder]/data-Bblp/    â†’ APO_Main/data-Bblp/\n",
    "[your_material_folder]/data-grain/   â†’ APO_Main/data-grain/\n",
    "[your_material_folder]/data-stretch/ â†’ APO_Main/data-stretch/\n",
    "```\n",
    "\n",
    "### 2. Backup Material to NAS\n",
    "- Copy your entire material folder to NAS server **data-pg8**\n",
    "\n",
    "### 3. Refine Presets in Max\n",
    "- Open Max patch\n",
    "- Load and test new sounds  \n",
    "- Adjust preset parameters for desired results\n",
    "\n",
    "### 4. Update Partitur Files\n",
    "- Create preset combinations in Max\n",
    "- Save to `partitur.txt` (outdoor) or `partitur_in.txt` (indoor)\n",
    "- Mirror partitur files to NAS **data-pg8** for brain control\n",
    "\n",
    "---\n",
    "\n",
    "**For detailed instructions, see: `readme.md` Section 10.4**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
